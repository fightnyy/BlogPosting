1

특정 주제에 대해 심도있게 논의하자!
Wizard와 Apprentice 와의 대화 Wizard를 Bot으로 대채 하는것이 목적

18 vpdlwl

하지만 이렇게 하니 Generative 모델이 원래 인풋 context 만 해서 인풋으로 받았기 때문에 Retrieval Next Utterance를 무시하려는 경향을 보였다. 그래서 실제로 이 모델을 학습시킬 때
Generated Next Utterance랑 Gold utterance를 비교를 해야하는데 Gold Utternce 를 실제 candidate 라벨이 있는 어떤 문장과 교체를 했다고 합니다. 그러니까 리트리버
모델에서 캔디데이트 라벨에서 직접 찾아 온 걸로 디코다가 말해라 라고 학습을 하기 위해서 알파 블렌딩 기술을 해준다고 합니다.

Dense Vector를 활용하는 Retrieve를 수행하되, Answer Extraction 을 수행하는 Document Reader와 관련 문서롤 뽑아오는 Passage Retrieve를 별도로 훈련하여 활용하는
방안을 제시함 Dense Retriever가 잘 훈련하기 위해선 Positive Sample과 Negative Sample을 잘 활용한 학습이 수행 되어야함 이러한 훈련에서 가장 중요한 Scheme은 어떻게
Negative Sample을 뽑을것인가?

총 3가지 실험:
Random : 데이터셋 내 임의의 문서를 Negative Sample로 설정 BM25 : 정답 스팬은 포함하지 않지만, BM25에 의해 높은 순위로 매겨진 문서를 Negative Sample로 설정 Gold :
다른 질문에 대한 답을 포함한 문서를 Negative Sample로 설정

가장 좋았던건 in batch negative Sampling 을 하면서 한개 정도의 BM25에서 문ㅅ거를 추가해주는것이 좋았다.
